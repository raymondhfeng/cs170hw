\begin{qunlist}
\q{$\bigstar$}{Course Syllabus}

Before you answer any of the following questions, please read over the syllabus carefully. The syllabus is pinned on the Piazza site. For each statement below, write \textit{OK} if it is allowed by the course policies and \textit{Not OK} otherwise.

\begin{enumerate}[(a)]
\item You ask a friend who took CS 170 previously for her homework solutions, some of which overlap with this semester's problem sets. You look at her solutions, then later write them down in your own words.
\begin{mdframed}
	\textbf{Solution} Not OK
\end{mdframed}

\item You had 5 midterms on the same day and are behind on your homework. You decide to ask your classmate, who's already done the homework, for help. He tells you how to do the first three problems.
\begin{mdframed}
	\textbf{Solution} Not OK
\end{mdframed}

\item You look up a problem online to search an algorithm, write it in your words and cite the source.
\begin{mdframed}
	\textbf{Solution} Not OK
\end{mdframed}

\item You were looking up Dijkstra's on the internet, and run into a website with a problem very similar to one on your homework. You read it, including the solution, and then you close the website, write up your solution, and cite the website URL in your homework writeup.
\begin{mdframed}
	\textbf{Solution} OK
\end{mdframed}

\item You are working on the homework in one of the TA's office hours with other people. You hear that student John Doe asked the TA if his solution is correct or not and the TA is explaining it. You join their conversation to understand what John has done.
\begin{mdframed}
	\textbf{Solution} NOT OK
\end{mdframed}

\end{enumerate}

\q{$\bigstar\bigstar$}{Asymptotic Complexity Comparisons}

\begin{enumerate}[(a)]
\item
Order the following functions so that $f_i \in O(f_j) \iff i \le j$. Do not
justify your answers.
\begin{enumerate}[(i)]
\item $f_1(n) = 3^{n}$
\item $f_2(n) = n^{1 \over 3}$
\item $f_3(n) = 12$
\item $f_4(n) = 2^{\log_2 n}$
\item $f_5(n) = \sqrt{n}$
\item $f_6(n) = 2^n$
\item $f_7(n) = \log_2 n$
\item $f_8(n) = 2^{\sqrt n}$
\item $f_9(n) = n^3$
\end{enumerate}
\begin{mdframed}
	\textbf{Solution} 
	$$O(12) \in O(\log_2(n)) \in O(n^{\frac{1}{3}}) \in O(n^{\frac{1}{2}}) \in O(2^{\log_2(n)}) \in O(n^3) \in O(2^{\sqrt{n}}) \in O(2^n) \in O(3^n)$$
	$$3,7,2,5,4,9,8,6,1$$
\end{mdframed}


\item
In each of the following, indicate whether $f = O(g)$, $f = \Omega(g)$, or both (in which case $f = \Theta(g)$). \textbf{\textit{Briefly}} justify each of your answers.

$\begin{tabu}{r l l}
    & f(n) & g(n) \\
(i) & \log_{3} n & \log_{4} n \\
(ii) & n \log (n^4) & n^2 \log (n^3) \\
(iii) & \sqrt[]{n} & (\log n)^3 \\
(iv) & 2^n & 2^{n+1} \\
(v) & n & (\log n)^{\log\log n} \\
(vi) & n + \log n & n + (\log n)^2 \\
(vii) & \log n! & n \log n \\
\end{tabu}$

\answer{\\
i. $$\frac{\ln(n)}{\ln(3)} \in \theta(\frac{\ln(n)}{\ln(4)}) \Rightarrow f \in \theta(g)$$
ii. $$\lim_{n\to\infty}\frac{4\log(n)}{3n\log(n)}=0$$
$$f \in O(g)$$
iii. $$\lim_{n\to\infty}\frac{\sqrt{n}}{(\log(3n))^3}$$
Take the derivative wrt n of numerator and denominator five times, and L'Hopital gives:
$$\lim_{n\to\infty}\frac{\sqrt{n}}{48} = \infty \Rightarrow f \in \Omega(g)$$
iv. $$\forall n \in \mathbb{R}, a*2^n \leq 2^{n+1} \leq b*2^n, a=\frac{1}{4}, b=4$$
$$f \in \theta(g)$$
v. 
$$n \in \Omega((\log(n))^{\log(\log(n))})$$
Because the log is not specified, I rewrite this as
$$n \in \Omega((\ln(n))^{\ln(\ln(n))})$$
Then, make the substitution $s = \ln(n)$
$$(s^{log_s(e)})^s \in \Omega(s^{\ln(s)})$$
Now we can just compare the exponents
$$s\frac{\ln(e)}{\ln(s)} \in \Omega(\ln(s))$$
This is true because
$$\lim_{s \to \infty}\frac{s}{(\ln(s))^2}=\infty$$
$$f \in \Omega(g)$$
vi. 
I omit the calculus.
$$\lim_{n\to\infty}\frac{f}{g} = 1 \Rightarrow f \in \theta(g)$$
vii.
$$(\frac{n}{2})^{\frac{n}{2}} \leq n!$$
$$\frac{n}{2}(\log(n) - \log(2)) \leq \log(n!)$$
$$n\log(n) \in O(\log(n!))$$
$$f \in \Omega(g)$$
$$\log(n!)=\log(n)+\log(n-1)+\log(n-2)+...$$
$$n\log(n)=\log(n)+\log(n)+...$$
$$n\log(n) \in \Omega(\log(n!))$$
$$f \in O(g)$$
$$f \in \Omega(g) \land f \in O(g) \Rightarrow f \in \theta(g)$$
}

\item Let $f(\cdot)$ be a function. Consider the equality
\[\sum_{i=1}^{n}f(i)\ \in \ \Theta(f(n)),\]
give a function $f_1$ such that the equality holds, and a function $f_2$ such that the equality does not hold.

\answer{
$$\sum_{i=1}^n2^n = 2^{n+1} \in \theta(2^n)$$
$$\sum{i=1}^nn = \frac{n(n+1)}{2} \in \theta(n^2){\tiny }$$
$$f_1(n) = 2^n, f_2(n) = n$$
}

\item Prove or disprove: If $f:\N\to\N$ is any positive-valued function,
then either (1) there exists a constant $c>0$ so that
$f(n) \in O(n^c)$, or (2) there exists a constant $\alpha>1$ so that
$f(n) \in \Omega(\alpha^n)$.

\answer{
False. There is a counterexample.
$$f(n)=\ceil{2^{\sqrt{n}}}$$
First.
$$2^{\sqrt{n}} \in \Omega(n^c))$$
$$2^{\sqrt{n}} \in \Omega(2^{\log_2(n^c)})$$
$$2^{\sqrt{n}} \in \Omega(2^{c\log_2(n)})$$
$$\sqrt{n} \in \Omega(c\log_2(n))$$
Also.
$$2^{\sqrt{n}} \in O(c^n))$$
$$2^{\sqrt{n}} \in O(2^{\log_2(c^n)}))$$
$$2^{\sqrt{n}} \in O(2^{n\log_2(c)}))$$
$$\sqrt{n} \in \in O(n\log_2(c))$$
$$f \in \Omega(n^c) \land f \in O(\alpha^n)$$
}
  
\end{enumerate}


\q{$\bigstar\bigstar\bigstar$}{Recurrence Relations}

Derive an asymptotic {\em tight} bound for the following $T(n)$. Cite any theorem you use.

\begin{enumerate}[(a)]

\item $T(n)=2\cdot T(\frac{n}{2})$ $+$ $\sqrt n$.

\answer{
Using the Master Theorem, we have:
$$a = 2, b = 2, d = \frac{1}{2}$$
$$T(n) \in \theta(n^{log_{b}(a)}) = \theta(n)$$
}

\item $T(n) = T(n-1) + c^n$ for constants $c>0$.

\answer{
Each call of the function on $n$ recursively calls itself on $n-1$, and then does $c^n$ work. The call $T(1)$ returns 1, and so all the work can be seen as the sum of $c^n$ from 2 to $n$. 
$$\sum_{i=2}^{n}c^i=\frac{a_1(1-r^n)}{1-r}=\frac{c^2(1-c^{n-1})}{1-c} \in \theta(c^n)$$   
Because we know that $c>0$, we can split this into cases:
$$c \in(0,1) \Rightarrow T(n) \in \theta(1)$$
$$c=1 \Rightarrow T(n) \in \theta(n)$$
$$c>1 \Rightarrow T(n) \in \theta(c^n)$$
}

\item $T(n) = 2T(\sqrt{n}) + 3$, and $T(2) = 3$.

\answer{
$$T(n) = 2T(\sqrt{n})+3$$
$$T(n) = 2(2T(\sqrt{\sqrt{n}})+3)+3$$
Because we are taking the square root of $n$ each time, and we stop when $n=2$, we can think of the recursion as halving the exponent each level deeper. Thus, because $n=2^{log_2(n)}$, the number of halvings before the exponent becomes 1 is $log(log(n))$. Thus:
$$T(n) = 2^{log(logn)}T(2)+3*\sum_{i=0}^{log(logn)} \in \theta(log(n))$$
}
 
\end{enumerate}


\q{$\bigstar\bigstar\bigstar\bigstar$}{Recurrence Relations Part II}

Solve the following recurrence relations and give a $\Theta$ bound for each of them.
\begin{enumerate}[(a)]
\item

\begin{enumerate}[(i)]
\item $T(n) = 3T(n/4) + 4n^2$\\
\answer{
Using the Master theorem, where
$$a=3, b=4, d=2, d > \log_b(a)$$
$$T(n) \in \theta(n^2)$$
}
\item $T(n) = 45T(n/3) + .1n^3$\\
\answer{	
Using the Master theorem, where 
$$a=45, b=3, d=3, d < \log_b(a)$$
$$T(n) \in \theta(n^{\log_3(45)})$$
}
\item $T(n) = 2T(\sqrt{n}) + 5$, and $T(2) = 5$. (Hint: this means the recursion tree stops when the problem size is $2$)\\
\answer{
	This is similar to problem 4.a.3, so we can go about it the same way. 
	$$T(n) = 2T(\sqrt{n}) + 5$$
	$$T(n) = 2((2T(\sqrt{\sqrt{n}} + 5))) + 5$$
	Thus, we know from before that there will be a depth of $\log(\log(n))$ in the recursive tree, and so we can express $T(n)$ as
	$$T(n) = 2^{\log(\log(n))}T(2) + 5*\sum_{i=0}^{\log(logn))}2^i \in \theta(\log(n))$$
}
\end{enumerate}
\item
\begin{enumerate}[(i)]
\item Consider the recurrence relation $T(n) = 2T(n/2) + n \log n$. We can't plug it directly into the Master theorem, so solve it by adding the size of each layer.
\textit{Hint: split up the $\log (n/(2^i))$ terms into $\log n - \log (2^i)$, and use the formula for arithmetic series.}\\
\answer{
From the recursion tree, we have the summation:
$$\sum_{i=0}^{log_2(n)}2^i\frac{n}{2^i}\log(\frac{n}{2^i})$$
$$=n*\sum_{i=0}^{log_2(n)}(\log(n)-i\log(2))$$
$$=n*\sum_{i=0}^{log_2(n)}\log(n) - n\log(2)\sum_{i=0}^{\log_2(n)}i$$
$$=n(\log(n))^2-(n\log(2))\frac{\log_2(n)(\log_2(n) + 1)}{2}$$
$$T(n) \in \theta(n(\log(n))^2)$$

}


\item A more general version of Master theorem, like the one on \href{https://en.wikipedia.org/wiki/Master_theorem}{Wikipedia}, incorporates this result. The case of the master theorem which applies to this problem is:

\textit{If $T(n) = aT(n/b) + f(n)$ where $a \geq 1$, $b > 1$, and $f(n) = \Theta(n^c \log^k n)$ where $c = \log_b a$, then $T(n) = \Theta(n^c \log^{k+1} n)$. }

Use the general Master theorem to solve the following recurrence relation:

$T(n) = 9T(n/3) + n^2 \log ^3 n$.

\answer{
Using the general Master theorem:
$$a=9, b=3, c=2, k=3$$
$$T(n)=\theta(n^2(\log(n))^4)$$
}
\end{enumerate} 
\end{enumerate}

\clearpage

\q{$\bigstar\bigstar\bigstar\bigstar$}{Two Sorted Arrays}

You are given two sorted arrays, each of size $n$. Give as efficient an algorithm as possible to find the $k$-th smallest element in the union of the two arrays. What is the running time of your algorithm as a function of $k$ and $n$?
{\em (You need to give a four-part solution for this problem.)}

\answer{\\ 
\textbf{Main Idea: } In order to take advantage of both arrays being sorted, notice that when looking at the medians of the two arrays, as well as the index desired, then at any step we can eliminate half of one array. Say we have our 2n elements, as well as two arrays A and B. Then there are a number of cases.
\begin{enumerate}
\item 
$k>n$, and median of A less than median of B. We can eliminate the lower half of A. And shift our k back by half of A in order to compensate. This is because if our index was in A, then it would have to be in the upper half. Suppose it was in the lower half. Then that means that there are $>\frac{n}{2}$ elements after it in the upper half of A. Furthermore, because the median of B is larger than that of A, then that means that there would also be $>\frac{n}{2}$ elements after it in the upper half of B. But this is impossible! It cannot be that there are both $>\frac{n}{2}$ elements greater than the kth element in both A and B, because that would mean $k>n$ is false. Thus, it must be valid to remove the lower half of A, as it is impossible for the kth element to be there. 
\item 
$k>n$, and median of A greater than median of B. With similar reasoning, eliminate the lower half of A and shift k back by half of A to compensate.
\item 
$k<n$, and median of A less median of B. With similar reasoning, eliminate the upper half of B. No need to shift k. 
\item 
$k<n$, and median of A greater than median of B. With similar reasoning, eliminate the upper half of A. No need to shift k. 
\end{enumerate}
\textbf{Pseudocode:} \\
kthElement(a, b, k)\\
\tab mid1 = middle element of first array\\
\tab mid2 = middle element of the second array\\
\tab if a has length 0\\
\tab \tab return kth element of b\\
\tab elif b has length 0\\
\tab \tab return kth element of a\\
\tab \tab if k is greater than sum of mid1 and mid 2\\
\tab \tab \tab if a[mid1] greater than b[mid2]\\
\tab \tab \tab \tab return kthElement(a, second half of b, k - mid2 - 1)\\
\tab \tab \tab else \\
\tab \tab \tab \tab return kthElement(second half of a, b, k - mid1 - 1)\\
\tab \tab else\\
\tab \tab \tab if a[mid1] greater than b[mid2]\\
\tab \tab \tab \tab return kthElement(first half of a, b, k)\\
\tab \tab \tab else \\
\tab \tab \tab \tab return kthElement(a, first half of b, k)\\
\textbf{Proof of Correctness} \\
\textbf{Proof by induction on $t=2n$}, the combined number of elements in the two arrays: \\
\textbf{Base case:} $n=1$, $t=2$. There are a number of options.
\begin{enumerate}
\item 
Two arrays of length 1: Then k can either be 1 or 2. If $k=1$, then eliminate the second array from our search, and if $k=2$, then eliminate the first array from our search. Either one of those options would lead us to our base case in the pseudocode, and return the element in the remaining array. 
\item 
One array of length 2: The other of length 0. This automatically goes to the base case, the case where there is only one non-zero array left. Then, simply get the desired element by indexing into the array. 
\end{enumerate}

\textbf{Inductive Hypothesis:} If we have total number of elements $t'$ where our algorithm is known to work, then our algorithm must also work for total number of elements $2t'$.
\\
\textbf{Inductive Step:} We do not assume that our proposed $2t'$ elements are split half and half, because this may not necessarily be the case somewhere along the execution of our algorithm. All we assume is that the $2t'$ elements are somehow split between two arrays. Using our trick of eliminating half of one of the two arrays, we can keep doing this until we reach $t'$ or less elements, where in which the problem is solved because of the inductive hypothesis. However, this may not be the case, as one of the arrays may be exhausted before the total number of elements between both arrays goes below $t'$. But one of the arrays are exhausted, our problem is also solved because the remaining array is in sorted order and can easily be indexed into for the desired element. 
 \\ 
\textbf{Running Time}$O(\log(n))$\\
\textbf{Justification}There are two lists of size n. In the worst case, we must half each list $\log(n)$ times until one reaches size 0. This will take $2\log(n)$ steps.
}

\q{$\bigstar\bigstar\bigstar\bigstar\bigstar$}{Merged Median} \\
Given $k$ sorted arrays of length $l$, design an efficient algorithm to finding the median element of all the $n=kl$ elements. Your algorithm should run  asymptotically faster than $O(n)$. Your answer from 5 may be helpful.

{\em (You need to give a four-part solution for this problem.)}

\answer{
	\\
\textbf{Main Idea}\\The main idea behind this algorithm is similar to that of problem 5. At any point in algorithm, half of either the largest array or smallest array can be removed.  \\
\textbf{Pseudocode}\\
mergedMedian(listOfArrays, medianIndex) \\
\tab If listOfArrays contains only one nonempty array \\
\tab \tab Get medianIndex of nonempty array \\
\tab Find the k medians of the k arrays. \\
\tab Find the two arrays with largest and smallest medians.\\
\tab Discard lower half of smallest median array.\\
\tab Discard upper half of largest median array. \\
\tab Modify median index by subtracting by number of elements discarded in lower half. \\
\tab Call mergedMedian(modifiedListOfArrays, modifiedMedianIndex) \\
\textbf{Proof of Correctness} \\
Loop invariant: $k_c:=\textbf{Desired index at current frame}, R_c:=\textbf{Total elements removed from left at current frame}$. 
$$\frac{n}{2}=k_c+R_c$$
\begin{enumerate}
	\item 
	The loop invariant is trivially true at the first frame. 
	\item 
	If the loop invariant is correct at frame $i$, then at frame $i+1$ there must have been some amount of items removed from the left. That amount is added to $R_c$ and removed from $k_c$, maintaining the loop invariant. 
	\item 
	If the invariant holds at bottom frame of my recursion, then I know that whatever I index to must me the median of the union of the arrays. This is because there are a total of $R_c$ smaller elements removed, and so $k_c$, if indexed in the right array, must be the index of the median.
\end{enumerate}
\textbf{Running Time} \\
$O(k\log(l))$\\
\textbf{Justification}\\
At the very worst, we halve all of the $k$ arrays $\log(l)$ times. However, if we also consider the fact that we need to calculate the max and min median of the k arrays at each step, we could do this efficiently by using two priority queues to contain all arrays and their medians, one for max one for min. After every step, we have to update the two arrays that were modified with their new medians, taking $\log(k)$ time. This leads to a runtime of $O(k\log(k)\log(l))$ 
}



\end{qunlist}
